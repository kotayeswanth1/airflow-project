{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e838b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6a987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1ffa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"beula.sam\") \\\n",
    "      .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad3207e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= spark.read.csv(r\"C:\\Users\\kotayaswanth\\Downloads\\timberland_stock.csv\", header = True)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5015c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+----+-----+---+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|year|month|day|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+----+-----+---+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|2012|    1|  3|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|2012|    1|  4|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|2012|    1|  5|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|2012|    1|  6|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|2012|    1|  9|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|2012|    1| 10|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|2012|    1| 11|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|2012|    1| 12|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|2012|    1| 13|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|2012|    1| 17|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+----+-----+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "\n",
    "df = df.withColumn(\"year\", year(df.Date))\n",
    "df = df.withColumn(\"month\", month(df.Date))\n",
    "df = df.withColumn(\"day\", dayofmonth(df.Date))\n",
    "\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e879fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"timber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ca04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"select Date,High from timber where High=(select max(High) from timber)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5518f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|      Date|     High|\n",
      "+----------+---------+\n",
      "|2015-01-13|90.970001|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af55d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       Mean_Close|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_close = spark.sql(\"select mean(Close) as Mean_Close from timber\")\n",
    "mean_close.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0c8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Min_Volume|\n",
      "+----------+\n",
      "|  10010500|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_volume = spark.sql(\"select min(Volume) as Min_Volume from timber\")\n",
    "min_volume.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dab21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Max_Volume|\n",
      "+----------+\n",
      "|   9994400|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_volume = spark.sql(\"select max(Volume) as Max_Volume from timber\")\n",
    "max_volume.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5512fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|No_of_days_is60|\n",
      "+---------------+\n",
      "|             81|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "close60dollars = spark.sql(\"select Date as Close_ls_60 from timber where Close<60.00\")\n",
    "close60dollars.createOrReplaceTempView(\"close60dollars\")\n",
    "count60close = spark.sql(\"select count(*) as No_of_days_is60 from close60dollars\")\n",
    "count60close.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "928bfe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       pearson_corr|\n",
      "+-------------------+\n",
      "|-0.3384326061737161|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pearson_corr = spark.sql(\"SELECT corr(High, Volume) AS pearson_corr from timber\")\n",
    "pearson_corr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6f9a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year| max_high|\n",
      "+----+---------+\n",
      "|2012|77.599998|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2015|90.970001|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_high_per_year = spark.sql(\"select year, max(High) as max_high from timber group by year\")\n",
    "max_high_per_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "715064a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|avg_close_monthly|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_close_per_month = spark.sql(\"select month, avg(Close) as avg_close_monthly from timber group by month order by month asc\")\n",
    "avg_close_per_month.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
